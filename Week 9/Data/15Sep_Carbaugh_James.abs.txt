Analysts tasked with developing probability density estimates may obtain data in sets of varying quality and quantity. Often low-fidelity data contaminated with measurement error, or “noise,” may be abundant, but the cost of obtaining data free of these errors will limit the amount of high-fidelity data available. In such a scenario, the problem is to identify an estimate of a probability density function given scarce high-fidelity observations, knowledge of measurement errors, abundant “noisy” data, and available user knowledge of the density apart from empirical data. We solve this rich class of deconvolution problems through constrained optimization with first-order epi-splines, which are used for the first time to approximate densities to an arbitrarily high level of precision. We limit our scope to univariate densities where measurement errors are homoscedastic. Demonstrations come from a benchmark from the literature, historical medical data, and a scenario in uncertainty quantification in fluid dynamics. Results show that deconvolution via epi-splines is viable, comparable with a widely available deconvolution method, and shows potential for savings in resource budgets for data collection.