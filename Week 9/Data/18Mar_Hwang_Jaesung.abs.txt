Most educational curricula have step-by-step learning objectives accompanied by some type of assessment that can be used to analyze student outcomes and trends. When these assessments are unstructured textual feedback, it is difficult to extract meaningful indicators that point to student success. In this thesis, we create a graphical representation of the text corpus of each individual student assessment in a flight-training program used by the Republic of Koreaâ€™s Air Force. From it, we develop a coherent topic model, which allows us to characterize the training program. We then utilize the graphical representation of student assessments, together with the extracted topic model, to extract meaningful information from each assessment. This allows us to develop a statistical model to predict student outcomes. This information also allows us to quantitatively assess the importance of each topic, characteristics of instructor feedback and their connection to student success, as well as other factors. We apply our methodology to the criticism text written in the flight-training program student evaluations in order to construct a model that accurately predicts passing and failing based on extracted factors. We provide instructors and students recommendations for improving the success rate of the flight-training course.